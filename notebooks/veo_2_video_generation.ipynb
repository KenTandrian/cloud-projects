{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjTHAV8FgEza"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdL4uvQQs76x"
      },
      "source": [
        "# Veo 2 Video Generation\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fvision%2Fgetting-started%2Fveo2_video_generation.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/vision/getting-started/veo2_video_generation.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHlR2zz1WbPA"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Katie Nguyen](https://github.com/katiemn) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDjAqcgigwdX"
      },
      "source": [
        "## Overview\n",
        "\n",
        "### Veo 2\n",
        "\n",
        "Veo 2 on Vertex AI brings Google's state of the art video generation capabilities to application developers. It's capable of creating videos with astonishing detail that simulate real-world physics across a wide range of visual styles.\n",
        "\n",
        "In this tutorial, you will learn how to use the Google Gen AI SDK for Python to interact with Veo 2 and generate new videos from text prompts and input images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2_iOv5uhXVg"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4uerc9Xhf1f"
      },
      "source": [
        "### Install Google Gen AI SDK for Python and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJyFNKoQhiwF"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet google-genai\n",
        "%pip install -q mediapy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWYnCW0-h6HI"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqz5LUG6h8fA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BgPMRz7Z6OF"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMQf_BkyiMgF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import urllib\n",
        "\n",
        "from PIL import Image as PIL_Image\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapy as media"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxBkUEqdiB1g"
      },
      "source": [
        "### Set Google Cloud project information and create client\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtjPBmYHiEfx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZcI2QHgXqrD"
      },
      "source": [
        "### Define a helper function to display media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb3R55ZEXrTx"
      },
      "outputs": [],
      "source": [
        "def show_video(gcs_uri):\n",
        "    file_name = gcs_uri.split(\"/\")[-1]\n",
        "    !gsutil cp {gcs_uri} {file_name}\n",
        "    media.show_video(media.read_video(file_name), height=500)\n",
        "\n",
        "\n",
        "def display_images(image) -> None:\n",
        "    fig, axis = plt.subplots(1, 1, figsize=(12, 6))\n",
        "    axis.imshow(image)\n",
        "    axis.set_title(\"Starting Image\")\n",
        "    axis.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XR9VXfDu9aQ"
      },
      "source": [
        "## Generate Videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPqMK1ucZjOo"
      },
      "source": [
        "### Load the video generation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlZsoOWpZiNz"
      },
      "outputs": [],
      "source": [
        "video_model = \"veo-2.0-generate-001\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-fgu9DvZmkU"
      },
      "source": [
        "### Generate videos from a text prompt\n",
        "\n",
        "With Veo 2, you have the option to generate 8 second videos from a text prompt. In order to generate a video in the following sample, specify the following info:\n",
        "- **Prompt:** A detailed description of the video you would like to see.\n",
        "- **Aspect ratio:** Select either 16:9 or 9:16.\n",
        "- **File location:** The generated video will be shown below with support from a previously defined helper function. The video will also be stored in Cloud Storage once video generation is complete. Specify the file path where you would like this video to be stored in the output_gcs field.\n",
        "- **Number of videos:** Set this value to 1 or 2.\n",
        "- **Video duration:** Can 5, 6, 7, or 8 seconds.\n",
        "- **Prompt enhancement:** The `veo-2.0-generate-001` model offers the option to enhance your provided prompt. To utilize this feature, set `enhance_prompt` to True. A new, detailed prompt will be created from your original one to help generate higher quality videos that better adhere to your prompt's intent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvI5uFC8ZoF1"
      },
      "outputs": [],
      "source": [
        "prompt = \"a cat reading a book\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "output_gcs = \"gs://\"  # @param {type: 'string'}\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        aspect_ratio=aspect_ratio,\n",
        "        output_gcs_uri=output_gcs,\n",
        "        number_of_videos=1,\n",
        "        duration_seconds=5,\n",
        "        person_generation=\"dont_allow\",\n",
        "        enhance_prompt=True,\n",
        "    ),\n",
        ")\n",
        "\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    show_video(operation.result.generated_videos[0].video.uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po3pB2-xZpvO"
      },
      "source": [
        "When generating videos of people you can also set the `person_generation` parameter accordingly:\n",
        "* `person_generation`: allow_adult, dont_allow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pjNKKajZqbZ"
      },
      "outputs": [],
      "source": [
        "prompt = \"sculpting a bowl on a pottery wheel\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"9:16\"  # @param [\"16:9\", \"9:16\"]\n",
        "output_gcs = \"gs://\"  # @param {type: 'string'}\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        aspect_ratio=aspect_ratio,\n",
        "        output_gcs_uri=output_gcs,\n",
        "        number_of_videos=1,\n",
        "        duration_seconds=7,\n",
        "        person_generation=\"allow_adult\",\n",
        "        enhance_prompt=True,\n",
        "    ),\n",
        ")\n",
        "\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    show_video(operation.result.generated_videos[0].video.uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSMY7p4lZ8y9"
      },
      "source": [
        "### Generate videos from an image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbfWxeoJtsWw"
      },
      "source": [
        "#### Load the starting image\n",
        "\n",
        "You can also generate a video by starting with an input image. Add the Cloud Storage file location of the image you'd like to use to display it below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcB2VhKVZSbB"
      },
      "outputs": [],
      "source": [
        "image_show = PIL_Image.open(\n",
        "    urllib.request.urlopen(\n",
        "        \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/flowers.png\"\n",
        "    )\n",
        ")\n",
        "display_images(image_show)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_bwA9hiMzL"
      },
      "source": [
        "#### Send the video request\n",
        "\n",
        "If you're generating a video from an image you don't need to provide a prompt. The model will simply add motion to your image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gNxNj9N2R4o"
      },
      "outputs": [],
      "source": [
        "prompt = \"flower garden on sunrise\"  # @param {type: 'string'}\n",
        "image_gcs = \"gs://cloud-samples-data/generative-ai/image/flowers.png\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "output_gcs = \"gs://\"  # @param {type: 'string'}\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    prompt=prompt,\n",
        "    image=types.Image(\n",
        "        gcs_uri=image_gcs,\n",
        "        mime_type=\"image/jpeg\",\n",
        "    ),\n",
        "    config=types.GenerateVideosConfig(\n",
        "        aspect_ratio=aspect_ratio,\n",
        "        output_gcs_uri=output_gcs,\n",
        "        number_of_videos=1,\n",
        "        duration_seconds=8,\n",
        "        person_generation=\"allow_adult\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    show_video(operation.result.generated_videos[0].video.uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Veo 2 Advanced Controls Features\n",
        "\n",
        "Veo 2 Advanced Controls is powered by a new foundation model developed in partnership with Google DeepMind. This release version provides the following core features.\n",
        "* Video Extend: Extend existing video by 4 to 7 seconds\n",
        "* Camera Controls: Precise and consistent control of camera motions through a dedicated API field\n",
        "* Interpolation: Generate videos using first and last frame as reference\n",
        "* Aspect Ratios: Landscape (16:9) & Portrait (9:16)\n",
        "* 720p resolution at 24 frames per second\n",
        "* Watermarking (synthID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "!pip install -q mediapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "video_model_advanced = \"veo-2.0-generate-exp\"\n",
        "os.environ['GENERATE_ENDPOINT']=\"https://us-central1-aiplatform.googleapis.com/v1beta1/projects/${PROJECT_ID}/locations/us-central1/publishers/google/models/${video_model_advanced}:predictLongRunning\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mediapy as media\n",
        "\n",
        "def show_video(gcs_uri):\n",
        "    file_name = gcs_uri.split(\"/\")[-1]\n",
        "    !gsutil cp {gcs_uri} {file_name}\n",
        "    media.show_video(media.read_video(file_name), height=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.genai.types import GenerateVideosOperation\n",
        "\n",
        "def wait_to_finish(operation_name: str):\n",
        "    \"\"\"Check the status of the video generation using the operation name\"\"\"\n",
        "    operation_name = operation_name.rstrip()\n",
        "    operation = client.operations.get(\n",
        "        GenerateVideosOperation(name=operation_name)\n",
        "    )\n",
        "\n",
        "    while not operation.done:\n",
        "        time.sleep(20)\n",
        "        operation = client.operations.get(operation)\n",
        "        print(operation)\n",
        "\n",
        "    print(operation.result.generated_videos)\n",
        "\n",
        "    if operation.response:\n",
        "        show_video(operation.result.generated_videos[0].video.uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Video Extend\n",
        "Veo 2 Advanced Controls offers a **Video Extend** feature that allows you to take an existing video and automatically generate an additional **4 to 7 seconds** of content, effectively extending its duration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash --out operation_name_str -s\n",
        "\n",
        "curl $GENERATE_ENDPOINT \\\n",
        "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-X \"POST\" \\\n",
        "-d '{\n",
        "    \"instances\": [{ \n",
        "        \"prompt\": \"Continue the scene of a cat smelling and biting a cup.\", \n",
        "        \"video\": {\"gcsUri\": \"gs://input-bucket/sample-video.mp4\", \"video\": \"video/mp4\"} \n",
        "    }], \n",
        "    \"parameters\": {\n",
        "        \"durationSeconds\": 7, \n",
        "        \"storageUri\": \"gs://output-bucket\"\n",
        "    }\n",
        "}' | jq -r '.name'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wait_to_finish(operation_name_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Camera Controls\n",
        "Veo 2 Advanced Controls offers a **Camera Controls** feature that allows you to select specific camera motions or effects when generating videos from text or image prompts. This provides you with precise and consistent control over the visual dynamics of your generated videos through a dedicated API field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash --out operation_name_str -s\n",
        "\n",
        "curl $GENERATE_ENDPOINT \\\n",
        "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-X \"POST\" \\\n",
        "-d '{\n",
        "  \"instances\": [{ \n",
        "    \"prompt\": \"A view of Sapporo Beer Museum Restaurant\", \n",
        "    \"image\": {\"gcsUri\": \"gs://input-bucket/sample-image.jpg\", \"mimeType\": \"image/jpg\"},\n",
        "    \"cameraControl\": \"TILT_DOWN\"\n",
        "  }], \n",
        "  \"parameters\": {\n",
        "    \"storageUri\": \"gs://output-bucket\"\n",
        "  }\n",
        "}' | jq -r '.name'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wait_to_finish(operation_name_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Video Interpolation\n",
        "Veo 2 Advanced Controls offers a **Video Interpolation** feature that allows you to generate new video frames to create a smooth transition between two provided images. This feature is useful for generating motion between keyframes or creating a video when you have a starting and an ending visual in mind."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash --out operation_name_str -s\n",
        "\n",
        "curl $GENERATE_ENDPOINT \\\n",
        "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-X \"POST\" \\\n",
        "-d '{\n",
        "  \"instances\": [{ \n",
        "    \"prompt\": \"A time-lapse video featuring a smooth day-to-night transition at Mount Moiwa, employing a slow zoom-in to highlight the changing light and the gradual appearance of the city nocturnal glow.\", \n",
        "    \"image\": {\"gcsUri\": \"gs://input-bucket/sample-image-1.jpg\", \"mimeType\": \"image/jpg\"},\n",
        "    \"lastFrame\": {\"gcsUri\": \"gs://input-bucket/sample-image-2.jpg\", \"mimeType\": \"image/jpg\"},\n",
        "  }], \n",
        "  \"parameters\": {\n",
        "    \"durationSeconds\": 8,\n",
        "    \"storageUri\": \"gs://output-bucket\"\n",
        "  }\n",
        "}' | jq -r '.name'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wait_to_finish(operation_name_str)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
